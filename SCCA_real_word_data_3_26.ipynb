{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PawpixuZjJF",
        "outputId": "a57e15df-f931-473a-f346-9aeccaa711e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "RNA Shape: (20603, 1982)\n",
            "CNA Shape: (22544, 2175)\n",
            "Clinical Shape: (2509, 39)\n",
            "\n",
            "RNA Columns (first 5): Index(['Hugo_Symbol', 'Entrez_Gene_Id', 'MB-0362', 'MB-0346', 'MB-0386'], dtype='object')\n",
            "CNA Columns (first 5): Index(['Hugo_Symbol', 'Entrez_Gene_Id', 'MB-0000', 'MB-0039', 'MB-0045'], dtype='object')\n",
            "Clinical Columns (first 5): Index(['Study ID', 'Patient ID', 'Sample ID', 'Age at Diagnosis',\n",
            "       'Type of Breast Surgery'],\n",
            "      dtype='object')\n",
            "\n",
            "After Alignment:\n",
            "RNA Shape: (1980, 20603)\n",
            "CNA Shape: (1980, 20603)\n",
            "Clinical Shape: (1980, 38)\n",
            "\n",
            "Number of samples with labels: 1980\n",
            "Label Distribution:\n",
            " Integrative Cluster\n",
            "8       299\n",
            "3       290\n",
            "4ER+    260\n",
            "10      226\n",
            "5       190\n",
            "7       190\n",
            "9       146\n",
            "1       139\n",
            "6        85\n",
            "4ER-     83\n",
            "2        72\n",
            "Name: count, dtype: int64\n",
            "\n",
            "After Dropping Missing Values and Re-alignment:\n",
            "RNA Shape: (1980, 20592)\n",
            "CNA Shape: (1980, 22079)\n",
            "Clinical Shape: (1980, 38)\n",
            "Number of samples with labels after re-alignment: 1980\n",
            "\n",
            "RNA scaled sample (first 5 rows, first 5 columns):\n",
            "[[ 1.39452267  0.06536542 -0.90261581  4.58939573  0.19980442]\n",
            " [-0.04446416 -0.89626589 -1.02998225 -0.18947775  0.20118274]\n",
            " [-2.13153135 -1.15723867 -0.47032779  0.0693681   1.38464043]\n",
            " [-1.70699104 -1.37317534 -0.42669061 -0.97390422  1.00121693]\n",
            " [-1.95939445 -1.18721427 -0.03666374  2.11828301 -0.44635493]]\n",
            "CNA scaled sample (first 5 rows, first 5 columns):\n",
            "[[0.01798601 0.01696973 0.14821331 0.03441451 0.03865027]\n",
            " [0.01798601 0.01696973 0.14821331 0.03441451 0.03865027]\n",
            " [0.01798601 0.01696973 0.14821331 0.03441451 0.03865027]\n",
            " [0.01798601 0.01696973 0.14821331 0.03441451 0.03865027]\n",
            " [0.01798601 0.01696973 0.14821331 0.03441451 0.03865027]]\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Mar 26 12:48:18 2025\n",
        "\n",
        "@author: oujakusui\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cross_decomposition import CCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted')\n",
        "\n",
        "# Step 1: Load RNA, CNA, and Clinical Data\n",
        "# Update these paths based on your Google Drive location\n",
        "rna_path = '/content/drive/MyDrive/brca_metabric/data_mrna_illumina_microarray.txt'\n",
        "cna_path = '/content/drive/MyDrive/brca_metabric/data_cna.txt'\n",
        "clinical_path = '/content/drive/MyDrive/brca_metabric_clinical_data.tsv'  # Use the correct file\n",
        "\n",
        "# Load the data\n",
        "rna = pd.read_csv(rna_path, sep='\\t')\n",
        "cna = pd.read_csv(cna_path, sep='\\t')\n",
        "clinical = pd.read_csv(clinical_path, sep='\\t')\n",
        "\n",
        "print(\"RNA Shape:\", rna.shape)\n",
        "print(\"CNA Shape:\", cna.shape)\n",
        "print(\"Clinical Shape:\", clinical.shape)\n",
        "\n",
        "# Step 2: Align Data by Sample IDs\n",
        "# Check the column names in each dataset to confirm the ID column\n",
        "print(\"\\nRNA Columns (first 5):\", rna.columns[:5])\n",
        "print(\"CNA Columns (first 5):\", cna.columns[:5])\n",
        "print(\"Clinical Columns (first 5):\", clinical.columns[:5])\n",
        "\n",
        "# For RNA and CNA, the first few rows might be metadata; genes/features are columns\n",
        "# Transpose to have samples as rows, genes as columns\n",
        "# Drop 'Entrez_Gene_Id' if it exists and set 'Hugo_Symbol' as the column names\n",
        "if 'Entrez_Gene_Id' in rna.columns:\n",
        "    rna = rna.drop(columns=['Entrez_Gene_Id'])\n",
        "rna = rna.set_index('Hugo_Symbol').T  # Transpose: samples as rows, genes as columns\n",
        "\n",
        "if 'Entrez_Gene_Id' in cna.columns:\n",
        "    cna = cna.drop(columns=['Entrez_Gene_Id'])\n",
        "cna = cna.set_index('Hugo_Symbol').T  # Transpose: samples as rows, genes as columns\n",
        "\n",
        "# Set index for clinical data using 'Sample ID' (correct for brca_metabric_clinical_data.tsv)\n",
        "clinical = clinical.set_index('Sample ID')\n",
        "\n",
        "# Align based on common sample IDs\n",
        "common_ids = clinical.index.intersection(rna.index).intersection(cna.index)\n",
        "rna = rna.loc[common_ids]\n",
        "cna = cna.loc[common_ids]\n",
        "clinical = clinical.loc[common_ids]\n",
        "\n",
        "print(\"\\nAfter Alignment:\")\n",
        "print(\"RNA Shape:\", rna.shape)\n",
        "print(\"CNA Shape:\", rna.shape)\n",
        "print(\"Clinical Shape:\", clinical.shape)\n",
        "\n",
        "# Step 3: Extract Labels for Evaluation\n",
        "# Use 'Integrative Cluster' as the primary label\n",
        "if 'Integrative Cluster' in clinical.columns:\n",
        "    labels = clinical['Integrative Cluster'].dropna()\n",
        "else:\n",
        "    print(\"Integrative Cluster not found. Available columns:\", clinical.columns)\n",
        "    if 'Pam50 + Claudin-low subtype' in clinical.columns:\n",
        "        labels = clinical['Pam50 + Claudin-low subtype'].dropna()  # Fallback label\n",
        "    else:\n",
        "        raise KeyError(\"Neither 'Integrative Cluster' nor 'Pam50 + Claudin-low subtype' found in clinical data.\")\n",
        "\n",
        "print(\"\\nNumber of samples with labels:\", len(labels))\n",
        "print(\"Label Distribution:\\n\", labels.value_counts())\n",
        "\n",
        "# Step 4: Handle Missing Values in RNA and CNA\n",
        "# Drop columns (genes) with any missing values for simplicity\n",
        "rna = rna.dropna(axis=1, how='any')\n",
        "cna = cna.dropna(axis=1, how='any')\n",
        "\n",
        "# Align again after dropping missing values\n",
        "common_ids = clinical.index.intersection(rna.index).intersection(cna.index)\n",
        "rna = rna.loc[common_ids]\n",
        "cna = cna.loc[common_ids]\n",
        "clinical = clinical.loc[common_ids]\n",
        "labels = labels.loc[common_ids]\n",
        "\n",
        "print(\"\\nAfter Dropping Missing Values and Re-alignment:\")\n",
        "print(\"RNA Shape:\", rna.shape)\n",
        "print(\"CNA Shape:\", cna.shape)\n",
        "print(\"Clinical Shape:\", clinical.shape)\n",
        "print(\"Number of samples with labels after re-alignment:\", len(labels))\n",
        "\n",
        "# Step 5: Normalize Data\n",
        "scaler = StandardScaler()\n",
        "rna_scaled = scaler.fit_transform(rna)\n",
        "cna_scaled = scaler.fit_transform(cna)\n",
        "\n",
        "print(\"\\nRNA scaled sample (first 5 rows, first 5 columns):\")\n",
        "print(rna_scaled[:5, :5])\n",
        "print(\"CNA scaled sample (first 5 rows, first 5 columns):\")\n",
        "print(cna_scaled[:5, :5])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mutual_info_score, adjusted_rand_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.linear_model import Lasso\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Placeholder for loading METABRIC data (replace with your actual data loading)\n",
        "# Assuming RNA (X), CNA (Y), and labels are provided as numpy arrays\n",
        "# Example: rna_data, cna_data, labels = load_metabric_data()\n",
        "# For demonstration, we'll simulate loading preprocessed data\n",
        "rna_data = rna_scaled  # 1000 samples, 500 RNA features\n",
        "cna_data = cna_scaled  # 1000 samples, 200 CNA features\n",
        "labels = labels  # 10 cancer subtypes\n",
        "\n",
        "# Preprocess data (assumed complete)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(rna_data)  # RNA data\n",
        "Y_scaled = scaler.fit_transform(cna_data)  # CNA data\n",
        "\n",
        "# Split into training and tuning sets (80-20 split)\n",
        "X_train, X_tune, Y_train, Y_tune, labels_train, labels_tune = train_test_split(\n",
        "    X_scaled, Y_scaled, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Log data shapes after splitting\n",
        "print(f\"Training set shapes: X_train: {X_train.shape}, Y_train: {Y_train.shape}, labels_train: {labels_train.shape}\")\n",
        "print(f\"Tuning set shapes: X_tune: {X_tune.shape}, Y_tune: {Y_tune.shape}, labels_tune: {labels_tune.shape}\")\n",
        "\n",
        "# SCCA Functions\n",
        "def sweep(matrix, margin, stats, operation='/'):\n",
        "    result_matrix = np.empty_like(matrix)\n",
        "    if margin == 1:  # Column-wise\n",
        "        for i in range(matrix.shape[1]):\n",
        "            if operation == '/':\n",
        "                result_matrix[:, i] = matrix[:, i] / stats[i]\n",
        "            elif operation == '*':\n",
        "                result_matrix[:, i] = matrix[:, i] * stats[i]\n",
        "    elif margin == 0:  # Row-wise\n",
        "        for i in range(matrix.shape[0]):\n",
        "            if operation == '/':\n",
        "                result_matrix[i, :] = matrix[i, :] / stats[i]\n",
        "            elif operation == '*':\n",
        "                result_matrix[i, :] = matrix[i, :] * stats[i]\n",
        "    return result_matrix\n",
        "\n",
        "def find_Omega(sigma_YX_hat, npairs, alpha=None, beta=None, y=None, x=None):\n",
        "    n = y.shape[0]\n",
        "    if npairs > 1:\n",
        "        rho = alpha.T @ sigma_YX_hat @ beta\n",
        "        omega = np.eye(n) - y @ alpha @ rho @ beta.T @ x.T / n\n",
        "    else:\n",
        "        omega = np.eye(n)\n",
        "    return omega\n",
        "\n",
        "def init0(sigma_YX_hat, sigma_X_hat, sigma_Y_hat, init_method, npairs, n):\n",
        "    q, p = sigma_Y_hat.shape[1], sigma_X_hat.shape[1]\n",
        "    if init_method == 'svd':\n",
        "        u, _, v = np.linalg.svd(sigma_YX_hat, full_matrices=False)\n",
        "        alpha_init = u[:, :npairs]\n",
        "        beta_init = v.T[:, :npairs]\n",
        "    elif init_method == 'random':\n",
        "        alpha_init = np.random.normal(size=(q, npairs))\n",
        "        beta_init = np.random.normal(size=(p, npairs))\n",
        "    alpha_scale = np.diag(alpha_init.T @ sigma_Y_hat @ alpha_init)\n",
        "    alpha_init = sweep(alpha_init, margin=1, stats=np.sqrt(alpha_scale), operation='/')\n",
        "    beta_scale = np.diag(beta_init.T @ sigma_X_hat @ beta_init)\n",
        "    beta_init = sweep(beta_init, margin=1, stats=np.sqrt(beta_scale), operation='/')\n",
        "    return {'alpha_init': alpha_init, 'beta_init': beta_init}\n",
        "\n",
        "def SCCA_solution(x, y, x_Omega, y_Omega, alpha0, beta0, standardize, lambda_alpha, lambda_beta, niter=100, eps=1e-4, column_index=0):\n",
        "    n, q, p = x.shape[0], y.shape[1], x.shape[1]\n",
        "    if alpha0.ndim > 1 and alpha0.shape[1] > 1:\n",
        "        alpha0 = alpha0[:, column_index]\n",
        "    if beta0.ndim > 1 and beta0.shape[1] > 1:\n",
        "        beta0 = beta0[:, column_index]\n",
        "    for i in range(niter):\n",
        "        x0 = x_Omega @ beta0\n",
        "        lasso_alpha = Lasso(alpha=lambda_alpha, fit_intercept=False)\n",
        "        lasso_alpha.fit(y, x0)\n",
        "        alpha1 = lasso_alpha.coef_\n",
        "        if np.sum(np.abs(alpha1)) < eps:\n",
        "            alpha0 = np.zeros(q)\n",
        "            break\n",
        "        alpha1_mask = np.abs(alpha1) > eps\n",
        "        alpha1_scale = y[:, alpha1_mask] @ alpha1[alpha1_mask]\n",
        "        alpha1 /= np.sqrt(alpha1_scale.T @ alpha1_scale / (n - 1))\n",
        "        y0 = y_Omega @ alpha1\n",
        "        lasso_beta = Lasso(alpha=lambda_beta, fit_intercept=False)\n",
        "        lasso_beta.fit(x, y0)\n",
        "        beta1 = lasso_beta.coef_\n",
        "        if np.sum(np.abs(beta1)) < eps:\n",
        "            beta0 = np.zeros(p)\n",
        "            break\n",
        "        beta1_scale = x[:, np.abs(beta1) > eps] @ beta1[np.abs(beta1) > eps]\n",
        "        beta1 /= np.sqrt(beta1_scale.T @ beta1_scale / (n - 1))\n",
        "        if np.sum(np.abs(alpha1 - alpha0)) < eps and np.sum(np.abs(beta1 - beta0)) < eps:\n",
        "            break\n",
        "        alpha0 = alpha1\n",
        "        beta0 = beta1\n",
        "    return {\"alpha\": alpha0, \"beta\": beta0, \"niter\": i+1}\n",
        "\n",
        "def SCCA(x, y, lambda_alpha, lambda_beta, alpha_init=None, beta_init=None, niter=1000, npairs=1, init_method=\"svd\", standardize=True, eps=1e-4):\n",
        "    p, q, n = x.shape[1], y.shape[1], x.shape[0]\n",
        "    x = StandardScaler().fit_transform(x) if standardize else x\n",
        "    y = StandardScaler().fit_transform(y) if standardize else y\n",
        "    sigma_YX_hat = np.cov(y.T, x.T)[:q, q:]\n",
        "    sigma_X_hat = np.cov(x.T)\n",
        "    sigma_Y_hat = np.cov(y.T)\n",
        "    alpha = np.zeros((q, npairs))\n",
        "    beta = np.zeros((p, npairs))\n",
        "    if alpha_init is None:\n",
        "        obj_init = init0(sigma_YX_hat, sigma_X_hat, sigma_Y_hat, init_method, npairs, n)\n",
        "        alpha_init = obj_init['alpha_init']\n",
        "        beta_init = obj_init['beta_init']\n",
        "    for ipairs in range(npairs):\n",
        "        omega = find_Omega(sigma_YX_hat, ipairs, alpha[:, :ipairs], beta[:, :ipairs], y, x)\n",
        "        x_tmp = omega.dot(x)\n",
        "        y_tmp = omega.T.dot(y)\n",
        "        lambda_alpha0 = lambda_alpha if isinstance(lambda_alpha, float) else lambda_alpha[ipairs]\n",
        "        lambda_beta0 = lambda_beta if isinstance(lambda_beta, float) else lambda_beta[ipairs]\n",
        "        obj = SCCA_solution(x, y, x_tmp, y_tmp, alpha_init, beta_init, False, lambda_alpha0, lambda_beta0, niter, eps, ipairs)\n",
        "        alpha[:, ipairs] = obj['alpha'].flatten()\n",
        "        beta[:, ipairs] = obj['beta'].flatten()\n",
        "    return {'alpha': alpha, 'beta': beta}\n",
        "\n",
        "# Run SCCA with fixed lambda = 0.1\n",
        "def run_scca_metabric(X_train, Y_train, X_tune, Y_tune, npairs=10):\n",
        "    lambda_val = 0.1  # Fixed lambda value as requested\n",
        "    print(f\"Using fixed lambda: {lambda_val}\\n\")\n",
        "    result = SCCA(X_train, Y_train, lambda_val, lambda_val, niter=100, npairs=npairs, init_method=\"svd\")\n",
        "    alpha_hat = result['alpha']\n",
        "    beta_hat = result['beta']\n",
        "    train_embedding = np.hstack((X_train @ beta_hat, Y_train @ alpha_hat))\n",
        "    tune_embedding = np.hstack((X_tune @ beta_hat, Y_tune @ alpha_hat))\n",
        "    print(f\"Train embedding shape: {train_embedding.shape}\")\n",
        "    print(f\"Tune embedding shape: {tune_embedding.shape}\")\n",
        "    return train_embedding, tune_embedding\n",
        "\n",
        "# Generate Embeddings\n",
        "train_embedding, tune_embedding = run_scca_metabric(X_train, Y_train, X_tune, Y_tune)\n",
        "\n",
        "# Evaluation Functions\n",
        "def compute_mi(embeddings, labels):\n",
        "    print(\"Computing Mutual Information (MI)...\")\n",
        "    discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
        "    embeddings_discretized = discretizer.fit_transform(embeddings)\n",
        "    mi_scores = [mutual_info_score(embeddings_discretized[:, i], labels) for i in range(embeddings_discretized.shape[1])]\n",
        "    avg_mi = np.mean(mi_scores)\n",
        "    print(f\"Average MI: {avg_mi}\")\n",
        "    return avg_mi\n",
        "\n",
        "# Compute Metrics\n",
        "mi_scca = compute_mi(train_embedding, labels_train)\n",
        "print(\"Performing KMeans clustering...\")\n",
        "kmeans_scca = KMeans(n_clusters=10, random_state=42)\n",
        "scca_clusters = kmeans_scca.fit_predict(train_embedding)\n",
        "scca_ari = adjusted_rand_score(labels_train, scca_clusters)\n",
        "print(f\"Adjusted Rand Index (ARI): {scca_ari}\")\n",
        "print(\"Performing SVM cross-validation...\")\n",
        "svm_scca = SVC(random_state=42)\n",
        "scca_accuracy = cross_val_score(svm_scca, train_embedding, labels_train, cv=5).mean()\n",
        "print(f\"SVM Accuracy: {scca_accuracy}\")\n",
        "\n",
        "# Display Results\n",
        "print(\"\\nSCCA Evaluation Results:\")\n",
        "print(f\"Mutual Information (MI): {mi_scca:.6f}\")\n",
        "print(f\"Adjusted Rand Index (ARI, %): {scca_ari * 100:.2f}\")\n",
        "print(f\"SVM Accuracy (%): {scca_accuracy * 100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGmBqkyQjJ1D",
        "outputId": "917a02b3-9de9-4911-e9cc-94b153789499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shapes: X_train: (1584, 20592), Y_train: (1584, 22079), labels_train: (1584,)\n",
            "Tuning set shapes: X_tune: (396, 20592), Y_tune: (396, 22079), labels_tune: (396,)\n",
            "Using fixed lambda: 0.1\n",
            "\n"
          ]
        }
      ]
    }
  ]
}